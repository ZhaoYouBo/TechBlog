<!DOCTYPE html>
<html lang="zh-cn">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
    
    <title>AI算法工程师 | 赵容博的个人博客</title>
    <meta name="viewport" content="width=device-width,minimum-scale=1">
    <meta name="description" content="AI 算法工程师（视觉感知方向）
岗位职责

相机硬件的选型、调试和标定等相关工作；
设计、开发和优化视觉算法和模型，以解决图像识别、目标检测、目标跟踪、图像分割等问题；
开发和推进基于深度学习的单目深度拟合、双目立体匹配算法应用落地；
调研和推进 3D 人体姿态估计算法、6D 物体姿态估计算法的评估和应用；
跟进基于深度学习的前沿视觉 SLAM 算法；
负责视觉算法开发、调试、部署和落地；

任职要求

熟悉相机 sensor 工作原理、ISP 图像处理流程、相机基本参数及标定, 了解图像质量的主客观评估标准；
熟悉主流的神经网络架构(ResNet、ViT 等)， 目标检测算法(如 YOLO、DETR 等)， 语义分割算法(Mask2Former、SAM 等)；
熟悉至少一种常用的单目深度拟合算法(如 DepthAnything 等), 至少熟悉一种双目立体匹配算法(如 LightStereo 等)；
了解主流的 3D 人体姿态估计算法(如 PoseFormer 等)或 6D 物体姿态估计算法(如 FoundationPose 等)的优先；
了解主流的端到端视觉 SLAM 算法(如 DROID-SLAM 等)， 了解基于 Gaussian Splatting 的 SLAM(如 SplaTAM)的优先；
熟练掌握 pytorch 等框架，熟悉常见的深度学习模型，并掌握相关的实现、训练、调优、部署等工作；
熟悉 C&#43;&#43;和 Python 编程语言，具备良好的编程习惯和较好的工程化能力；
具有计算机科学、电子工程或相关专业全日制本科及以上学历； 2 年及以上工作经验。

学习计划
第一阶段：硬件基础与算法框架（1-3个月）
目标：掌握相机硬件全流程与深度学习基础能力

相机硬件专项（4周）

学习《Computer Vision: Algorithms and Applications》第2章（成像原理）
实践OpenCV相机标定模块（张正友标定法）
使用MATLAB/ROS工具进行ISP流程模拟实验
搭建图像质量评估体系（PSNR/SSIM → 新指标：LPIPS/CSIQ）


算法框架升级（4周）

深度学习框架：

PyTorch高级特性（分布式训练/量化部署）
ONNX/TensorRT部署实战（YOLOv8部署案例）


搭建算法基线：

复现YOLOv8改进策略（损失函数/标签分配）
实现Mask2Former的实例分割pipeline





第二阶段：立体视觉与深度估计（4-6个月）
目标：建立三维视觉技术栈">
    <meta name="generator" content="Hugo 0.147.2">
    
    
    
      <meta name="robots" content="index, follow">
    
    

    
<link rel="stylesheet" href="/TechBlog/ananke/css/main.min.d05fb5f317fcf33b3a52936399bdf6f47dc776516e1692e412ec7d76f4a5faa2.css" >




    


    
      

    

    

    
      <link rel="canonical" href="https://zhaoyoubo.github.io/TechBlog/posts/ai%E7%AE%97%E6%B3%95%E5%B7%A5%E7%A8%8B%E5%B8%88/">
    

    <meta property="og:url" content="https://zhaoyoubo.github.io/TechBlog/posts/ai%E7%AE%97%E6%B3%95%E5%B7%A5%E7%A8%8B%E5%B8%88/">
  <meta property="og:site_name" content="赵容博的个人博客">
  <meta property="og:title" content="AI算法工程师">
  <meta property="og:description" content="AI 算法工程师（视觉感知方向） 岗位职责 相机硬件的选型、调试和标定等相关工作； 设计、开发和优化视觉算法和模型，以解决图像识别、目标检测、目标跟踪、图像分割等问题； 开发和推进基于深度学习的单目深度拟合、双目立体匹配算法应用落地； 调研和推进 3D 人体姿态估计算法、6D 物体姿态估计算法的评估和应用； 跟进基于深度学习的前沿视觉 SLAM 算法； 负责视觉算法开发、调试、部署和落地； 任职要求 熟悉相机 sensor 工作原理、ISP 图像处理流程、相机基本参数及标定, 了解图像质量的主客观评估标准； 熟悉主流的神经网络架构(ResNet、ViT 等)， 目标检测算法(如 YOLO、DETR 等)， 语义分割算法(Mask2Former、SAM 等)； 熟悉至少一种常用的单目深度拟合算法(如 DepthAnything 等), 至少熟悉一种双目立体匹配算法(如 LightStereo 等)； 了解主流的 3D 人体姿态估计算法(如 PoseFormer 等)或 6D 物体姿态估计算法(如 FoundationPose 等)的优先； 了解主流的端到端视觉 SLAM 算法(如 DROID-SLAM 等)， 了解基于 Gaussian Splatting 的 SLAM(如 SplaTAM)的优先； 熟练掌握 pytorch 等框架，熟悉常见的深度学习模型，并掌握相关的实现、训练、调优、部署等工作； 熟悉 C&#43;&#43;和 Python 编程语言，具备良好的编程习惯和较好的工程化能力； 具有计算机科学、电子工程或相关专业全日制本科及以上学历； 2 年及以上工作经验。 学习计划 第一阶段：硬件基础与算法框架（1-3个月） 目标：掌握相机硬件全流程与深度学习基础能力
相机硬件专项（4周） 学习《Computer Vision: Algorithms and Applications》第2章（成像原理） 实践OpenCV相机标定模块（张正友标定法） 使用MATLAB/ROS工具进行ISP流程模拟实验 搭建图像质量评估体系（PSNR/SSIM → 新指标：LPIPS/CSIQ） 算法框架升级（4周） 深度学习框架： PyTorch高级特性（分布式训练/量化部署） ONNX/TensorRT部署实战（YOLOv8部署案例） 搭建算法基线： 复现YOLOv8改进策略（损失函数/标签分配） 实现Mask2Former的实例分割pipeline 第二阶段：立体视觉与深度估计（4-6个月） 目标：建立三维视觉技术栈">
  <meta property="og:locale" content="zh_cn">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2025-05-12T16:17:45+08:00">
    <meta property="article:modified_time" content="2025-05-12T16:17:45+08:00">

  <meta itemprop="name" content="AI算法工程师">
  <meta itemprop="description" content="AI 算法工程师（视觉感知方向） 岗位职责 相机硬件的选型、调试和标定等相关工作； 设计、开发和优化视觉算法和模型，以解决图像识别、目标检测、目标跟踪、图像分割等问题； 开发和推进基于深度学习的单目深度拟合、双目立体匹配算法应用落地； 调研和推进 3D 人体姿态估计算法、6D 物体姿态估计算法的评估和应用； 跟进基于深度学习的前沿视觉 SLAM 算法； 负责视觉算法开发、调试、部署和落地； 任职要求 熟悉相机 sensor 工作原理、ISP 图像处理流程、相机基本参数及标定, 了解图像质量的主客观评估标准； 熟悉主流的神经网络架构(ResNet、ViT 等)， 目标检测算法(如 YOLO、DETR 等)， 语义分割算法(Mask2Former、SAM 等)； 熟悉至少一种常用的单目深度拟合算法(如 DepthAnything 等), 至少熟悉一种双目立体匹配算法(如 LightStereo 等)； 了解主流的 3D 人体姿态估计算法(如 PoseFormer 等)或 6D 物体姿态估计算法(如 FoundationPose 等)的优先； 了解主流的端到端视觉 SLAM 算法(如 DROID-SLAM 等)， 了解基于 Gaussian Splatting 的 SLAM(如 SplaTAM)的优先； 熟练掌握 pytorch 等框架，熟悉常见的深度学习模型，并掌握相关的实现、训练、调优、部署等工作； 熟悉 C&#43;&#43;和 Python 编程语言，具备良好的编程习惯和较好的工程化能力； 具有计算机科学、电子工程或相关专业全日制本科及以上学历； 2 年及以上工作经验。 学习计划 第一阶段：硬件基础与算法框架（1-3个月） 目标：掌握相机硬件全流程与深度学习基础能力
相机硬件专项（4周） 学习《Computer Vision: Algorithms and Applications》第2章（成像原理） 实践OpenCV相机标定模块（张正友标定法） 使用MATLAB/ROS工具进行ISP流程模拟实验 搭建图像质量评估体系（PSNR/SSIM → 新指标：LPIPS/CSIQ） 算法框架升级（4周） 深度学习框架： PyTorch高级特性（分布式训练/量化部署） ONNX/TensorRT部署实战（YOLOv8部署案例） 搭建算法基线： 复现YOLOv8改进策略（损失函数/标签分配） 实现Mask2Former的实例分割pipeline 第二阶段：立体视觉与深度估计（4-6个月） 目标：建立三维视觉技术栈">
  <meta itemprop="datePublished" content="2025-05-12T16:17:45+08:00">
  <meta itemprop="dateModified" content="2025-05-12T16:17:45+08:00">
  <meta itemprop="wordCount" content="160">
  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="AI算法工程师">
  <meta name="twitter:description" content="AI 算法工程师（视觉感知方向） 岗位职责 相机硬件的选型、调试和标定等相关工作； 设计、开发和优化视觉算法和模型，以解决图像识别、目标检测、目标跟踪、图像分割等问题； 开发和推进基于深度学习的单目深度拟合、双目立体匹配算法应用落地； 调研和推进 3D 人体姿态估计算法、6D 物体姿态估计算法的评估和应用； 跟进基于深度学习的前沿视觉 SLAM 算法； 负责视觉算法开发、调试、部署和落地； 任职要求 熟悉相机 sensor 工作原理、ISP 图像处理流程、相机基本参数及标定, 了解图像质量的主客观评估标准； 熟悉主流的神经网络架构(ResNet、ViT 等)， 目标检测算法(如 YOLO、DETR 等)， 语义分割算法(Mask2Former、SAM 等)； 熟悉至少一种常用的单目深度拟合算法(如 DepthAnything 等), 至少熟悉一种双目立体匹配算法(如 LightStereo 等)； 了解主流的 3D 人体姿态估计算法(如 PoseFormer 等)或 6D 物体姿态估计算法(如 FoundationPose 等)的优先； 了解主流的端到端视觉 SLAM 算法(如 DROID-SLAM 等)， 了解基于 Gaussian Splatting 的 SLAM(如 SplaTAM)的优先； 熟练掌握 pytorch 等框架，熟悉常见的深度学习模型，并掌握相关的实现、训练、调优、部署等工作； 熟悉 C&#43;&#43;和 Python 编程语言，具备良好的编程习惯和较好的工程化能力； 具有计算机科学、电子工程或相关专业全日制本科及以上学历； 2 年及以上工作经验。 学习计划 第一阶段：硬件基础与算法框架（1-3个月） 目标：掌握相机硬件全流程与深度学习基础能力
相机硬件专项（4周） 学习《Computer Vision: Algorithms and Applications》第2章（成像原理） 实践OpenCV相机标定模块（张正友标定法） 使用MATLAB/ROS工具进行ISP流程模拟实验 搭建图像质量评估体系（PSNR/SSIM → 新指标：LPIPS/CSIQ） 算法框架升级（4周） 深度学习框架： PyTorch高级特性（分布式训练/量化部署） ONNX/TensorRT部署实战（YOLOv8部署案例） 搭建算法基线： 复现YOLOv8改进策略（损失函数/标签分配） 实现Mask2Former的实例分割pipeline 第二阶段：立体视觉与深度估计（4-6个月） 目标：建立三维视觉技术栈">

      
    
	
  </head><body class="ma0 avenir bg-near-white production">

    
   
  

  <header>
    <div class="bg-black">
      <nav class="pv3 ph3 ph4-ns" role="navigation">
  <div class="flex-l center items-center justify-between">
    <a href="/TechBlog/" class="f3 fw2 hover-white white-90 dib no-underline">
      
        赵容博的个人博客
      
    </a>
    <div class="flex-l items-center">
      

      
      <div class="ananke-socials"></div>

    </div>
  </div>
</nav>

    </div>
  </header>



    <main class="pb7" role="main">
      
  
  
  <article class="flex-l mw8 center ph3 flex-wrap justify-between">
    <header class="mt4 w-100">
      <aside class="instapaper_ignoref b helvetica tracked ttu">
          
        Posts
      </aside><div id="sharing" class="mt3 ananke-socials"></div>
<h1 class="f1 athelas mt3 mb1">AI算法工程师</h1>
      
      
      
      <time class="f6 mv4 dib tracked" datetime="2025-05-12T16:17:45+08:00">May 12, 2025</time>
      

      
      
    </header>
    <div class="nested-copy-line-height lh-copy serif f4 nested-links mid-gray pr4-l w-two-thirds-l"><h1 id="ai-算法工程师视觉感知方向">AI 算法工程师（视觉感知方向）</h1>
<h2 id="岗位职责">岗位职责</h2>
<ol>
<li>相机硬件的选型、调试和标定等相关工作；</li>
<li>设计、开发和优化视觉算法和模型，以解决图像识别、目标检测、目标跟踪、图像分割等问题；</li>
<li>开发和推进基于深度学习的单目深度拟合、双目立体匹配算法应用落地；</li>
<li>调研和推进 3D 人体姿态估计算法、6D 物体姿态估计算法的评估和应用；</li>
<li>跟进基于深度学习的前沿视觉 SLAM 算法；</li>
<li>负责视觉算法开发、调试、部署和落地；</li>
</ol>
<h2 id="任职要求">任职要求</h2>
<ol>
<li>熟悉相机 sensor 工作原理、ISP 图像处理流程、相机基本参数及标定, 了解图像质量的主客观评估标准；</li>
<li>熟悉主流的神经网络架构(ResNet、ViT 等)， 目标检测算法(如 YOLO、DETR 等)， 语义分割算法(Mask2Former、SAM 等)；</li>
<li>熟悉至少一种常用的单目深度拟合算法(如 DepthAnything 等), 至少熟悉一种双目立体匹配算法(如 LightStereo 等)；</li>
<li>了解主流的 3D 人体姿态估计算法(如 PoseFormer 等)或 6D 物体姿态估计算法(如 FoundationPose 等)的优先；</li>
<li>了解主流的端到端视觉 SLAM 算法(如 DROID-SLAM 等)， 了解基于 Gaussian Splatting 的 SLAM(如 SplaTAM)的优先；</li>
<li>熟练掌握 pytorch 等框架，熟悉常见的深度学习模型，并掌握相关的实现、训练、调优、部署等工作；</li>
<li>熟悉 C++和 Python 编程语言，具备良好的编程习惯和较好的工程化能力；</li>
<li>具有计算机科学、电子工程或相关专业全日制本科及以上学历； 2 年及以上工作经验。</li>
</ol>
<h1 id="学习计划">学习计划</h1>
<h2 id="第一阶段硬件基础与算法框架1-3个月">第一阶段：硬件基础与算法框架（1-3个月）</h2>
<p><strong>目标</strong>：掌握相机硬件全流程与深度学习基础能力</p>
<ol>
<li><strong>相机硬件专项</strong>（4周）
<ul>
<li>学习《Computer Vision: Algorithms and Applications》第2章（成像原理）</li>
<li>实践OpenCV相机标定模块（张正友标定法）</li>
<li>使用MATLAB/ROS工具进行ISP流程模拟实验</li>
<li>搭建图像质量评估体系（PSNR/SSIM → 新指标：LPIPS/CSIQ）</li>
</ul>
</li>
<li><strong>算法框架升级</strong>（4周）
<ul>
<li>深度学习框架：
<ul>
<li>PyTorch高级特性（分布式训练/量化部署）</li>
<li>ONNX/TensorRT部署实战（YOLOv8部署案例）</li>
</ul>
</li>
<li>搭建算法基线：
<ul>
<li>复现YOLOv8改进策略（损失函数/标签分配）</li>
<li>实现Mask2Former的实例分割pipeline</li>
</ul>
</li>
</ul>
</li>
</ol>
<h2 id="第二阶段立体视觉与深度估计4-6个月">第二阶段：立体视觉与深度估计（4-6个月）</h2>
<p><strong>目标</strong>：建立三维视觉技术栈</p>
<ol>
<li><strong>单目深度估计</strong>（4周）
<ul>
<li>精读Depth Anything论文（CVPR 2024）</li>
<li>使用NYU Depth V2数据集训练改进模型</li>
<li>设计轻量化方案（知识蒸馏→移动端部署）</li>
</ul>
</li>
<li><strong>双目立体匹配</strong>（4周）
<ul>
<li>研究LightStereo的工业级优化策略</li>
<li>在SceneFlow数据集上开展对比实验</li>
<li>开发FPGA加速方案（HLS代码优化）</li>
</ul>
</li>
<li><strong>3D姿态估计</strong>（4周）
<ul>
<li>复现PoseFormer的时序建模模块</li>
<li>在Human3.6M数据集上优化推理速度</li>
<li>探索FoundationPose的zero-shot能力</li>
</ul>
</li>
</ol>
<h2 id="第三阶段slam与前沿技术7-9个月">第三阶段：SLAM与前沿技术（7-9个月）</h2>
<p><strong>目标</strong>：构建SLAM技术体系并追踪前沿</p>
<ol>
<li><strong>经典SLAM系统</strong>（5周）
<ul>
<li>手撕ORB-SLAM3核心模块（特征提取/优化）</li>
<li>在TUM数据集上完成完整轨迹评测</li>
<li>开发ROS实时运行系统</li>
</ul>
</li>
<li><strong>深度学习SLAM</strong>（4周）
<ul>
<li>分析DROID-SLAM的BA优化策略</li>
<li>复现SplaTAM的Gaussian Splatting实现</li>
<li>在Replica数据集进行三维重建对比</li>
</ul>
</li>
<li><strong>论文精读计划</strong>（持续）
<ul>
<li>每周精读2篇CVPR/ICCV最新论文</li>
<li>建立技术趋势分析文档（GitHub仓库维护）</li>
</ul>
</li>
</ol>
<h2 id="第四阶段工程化实战10-12个月">第四阶段：工程化实战（10-12个月）</h2>
<p><strong>目标</strong>：打造完整的项目闭环</p>
<ol>
<li><strong>工业级项目开发</strong>（8周）
<ul>
<li>设计端到端视觉系统：从相机选型（IMX477 vs OV4689）到算法部署</li>
<li>开发自动化标定工具链（含异常检测模块）</li>
<li>构建质量监控系统（Drift检测/在线校准）</li>
</ul>
</li>
<li><strong>性能优化专项</strong>（4周）
<ul>
<li>算法级优化：模型剪枝（LayerDrop）</li>
<li>硬件级优化：GPU TensorCore加速</li>
<li>系统级优化：多线程流水线设计</li>
</ul>
</li>
<li><strong>作品集构建</strong>（持续）
<ul>
<li>GitHub维护3个高质量项目：
<ol>
<li>实时多目标跟踪系统</li>
<li>嵌入式双目深度解决方案</li>
<li>基于NeRF的SLAM系统</li>
</ol>
</li>
<li>撰写技术博客（Medium/知乎专栏）</li>
</ul>
</li>
</ol>
<h2 id="学习资源推荐">学习资源推荐：</h2>
<ol>
<li>硬件方向：《CMOS图像传感器电路设计》</li>
<li>算法方向：《Multiple View Geometry in Computer Vision》</li>
<li>工程实践：《CUDA C++ Best Practices Guide》</li>
<li>论文库：CVF Open Access + arXiv每日推送</li>
</ol>
<h2 id="关键实施策略">关键实施策略：</h2>
<ol>
<li>建立技术雷达图：每月更新各技术维度能力值</li>
<li>参与Kaggle竞赛：至少完成2个计算机视觉赛事</li>
<li>硬件投入：搭建含Jetson Orin+工业相机的开发平台</li>
<li>参加CVPR/IROS等会议（线上资源）了解工业界最新需求</li>
</ol>
<p>建议每周保持30小时有效学习时间（含项目实践），重点关注技术深度的纵向突破而非广度覆盖，每阶段结束时输出可展示的成果物。同时建议与行业从业者保持交流（如GitHub贡献、技术社区答疑），培养工程思维和产品意识。</p>
<ul class="pa0">
  
</ul>
<div class="mt6 instapaper_ignoref">
      
      
      </div>
    </div>

    <aside class="w-30-l mt6-l">




</aside>

  </article>

    </main>
    <footer class="bg-black bottom-0 w-100 pa3" role="contentinfo">
  <div class="flex justify-between">
  <a class="f4 fw4 hover-white white-70 dn dib-ns pv2 ph3 no-underline" href="https://zhaoyoubo.github.io/TechBlog/" >
    &copy;  赵容博的个人博客 2025 
  </a>
    <div><div class="ananke-socials"></div>
</div>
  </div>
</footer>

  </body>
</html>

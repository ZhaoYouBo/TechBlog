<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>赵容博的博客</title>
    <link>https://zhaoyoubo.github.io/TechBlog/</link>
    <description>赵容博的博客</description>
    <generator>Hugo 0.147.2 &amp; FixIt v0.3.21-a85a6655</generator>
    <language>en-us</language>
    <lastBuildDate>Tue, 13 May 2025 14:06:38 +0800</lastBuildDate>
    <atom:link href="https://zhaoyoubo.github.io/TechBlog/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>AI算法工程师</title>
      <link>https://zhaoyoubo.github.io/TechBlog/posts/3e78a2f/</link>
      <pubDate>Tue, 13 May 2025 14:06:38 +0800</pubDate>
      <guid>https://zhaoyoubo.github.io/TechBlog/posts/3e78a2f/</guid>
      <category domain="https://zhaoyoubo.github.io/TechBlog/categories/draft/">Draft</category>
      <description>&lt;h2 class=&#34;heading-element&#34; id=&#34;ai-算法工程师视觉感知方向&#34;&gt;&lt;span&gt;AI 算法工程师（视觉感知方向）&lt;/span&gt;&#xD;&#xA;  &lt;a href=&#34;#ai-%e7%ae%97%e6%b3%95%e5%b7%a5%e7%a8%8b%e5%b8%88%e8%a7%86%e8%a7%89%e6%84%9f%e7%9f%a5%e6%96%b9%e5%90%91&#34; class=&#34;heading-mark&#34;&gt;&#xD;&#xA;    &lt;svg class=&#34;octicon octicon-link&#34; viewBox=&#34;0 0 16 16&#34; version=&#34;1.1&#34; width=&#34;16&#34; height=&#34;16&#34; aria-hidden=&#34;true&#34;&gt;&lt;path d=&#34;m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z&#34;&gt;&lt;/path&gt;&lt;/svg&gt;&#xD;&#xA;  &lt;/a&gt;&#xD;&#xA;&lt;/h2&gt;&lt;h3 class=&#34;heading-element&#34; id=&#34;岗位职责&#34;&gt;&lt;span&gt;岗位职责&lt;/span&gt;&#xD;&#xA;  &lt;a href=&#34;#%e5%b2%97%e4%bd%8d%e8%81%8c%e8%b4%a3&#34; class=&#34;heading-mark&#34;&gt;&#xD;&#xA;    &lt;svg class=&#34;octicon octicon-link&#34; viewBox=&#34;0 0 16 16&#34; version=&#34;1.1&#34; width=&#34;16&#34; height=&#34;16&#34; aria-hidden=&#34;true&#34;&gt;&lt;path d=&#34;m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z&#34;&gt;&lt;/path&gt;&lt;/svg&gt;&#xD;&#xA;  &lt;/a&gt;&#xD;&#xA;&lt;/h3&gt;&lt;ol&gt;&#xA;&lt;li&gt;相机硬件的选型、调试和标定等相关工作；&lt;/li&gt;&#xA;&lt;li&gt;设计、开发和优化视觉算法和模型，以解决图像识别、目标检测、目标跟踪、图像分割等问题；&lt;/li&gt;&#xA;&lt;li&gt;开发和推进基于深度学习的单目深度拟合、双目立体匹配算法应用落地；&lt;/li&gt;&#xA;&lt;li&gt;调研和推进 3D 人体姿态估计算法、6D 物体姿态估计算法的评估和应用；&lt;/li&gt;&#xA;&lt;li&gt;跟进基于深度学习的前沿视觉 SLAM 算法；&lt;/li&gt;&#xA;&lt;li&gt;负责视觉算法开发、调试、部署和落地；&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h3 class=&#34;heading-element&#34; id=&#34;任职要求&#34;&gt;&lt;span&gt;任职要求&lt;/span&gt;&#xD;&#xA;  &lt;a href=&#34;#%e4%bb%bb%e8%81%8c%e8%a6%81%e6%b1%82&#34; class=&#34;heading-mark&#34;&gt;&#xD;&#xA;    &lt;svg class=&#34;octicon octicon-link&#34; viewBox=&#34;0 0 16 16&#34; version=&#34;1.1&#34; width=&#34;16&#34; height=&#34;16&#34; aria-hidden=&#34;true&#34;&gt;&lt;path d=&#34;m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z&#34;&gt;&lt;/path&gt;&lt;/svg&gt;&#xD;&#xA;  &lt;/a&gt;&#xD;&#xA;&lt;/h3&gt;&lt;ol&gt;&#xA;&lt;li&gt;熟悉相机 sensor 工作原理、ISP 图像处理流程、相机基本参数及标定, 了解图像质量的主客观评估标准；&lt;/li&gt;&#xA;&lt;li&gt;熟悉主流的神经网络架构(ResNet、ViT 等)， 目标检测算法(如 YOLO、DETR 等)， 语义分割算法(Mask2Former、SAM 等)；&lt;/li&gt;&#xA;&lt;li&gt;熟悉至少一种常用的单目深度拟合算法(如 DepthAnything 等), 至少熟悉一种双目立体匹配算法(如 LightStereo 等)；&lt;/li&gt;&#xA;&lt;li&gt;了解主流的 3D 人体姿态估计算法(如 PoseFormer 等)或 6D 物体姿态估计算法(如 FoundationPose 等)的优先；&lt;/li&gt;&#xA;&lt;li&gt;了解主流的端到端视觉 SLAM 算法(如 DROID-SLAM 等)， 了解基于 Gaussian Splatting 的 SLAM(如 SplaTAM)的优先；&lt;/li&gt;&#xA;&lt;li&gt;熟练掌握 pytorch 等框架，熟悉常见的深度学习模型，并掌握相关的实现、训练、调优、部署等工作；&lt;/li&gt;&#xA;&lt;li&gt;熟悉 C++和 Python 编程语言，具备良好的编程习惯和较好的工程化能力；&lt;/li&gt;&#xA;&lt;li&gt;具有计算机科学、电子工程或相关专业全日制本科及以上学历； 2 年及以上工作经验。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h2 class=&#34;heading-element&#34; id=&#34;学习计划&#34;&gt;&lt;span&gt;学习计划&lt;/span&gt;&#xD;&#xA;  &lt;a href=&#34;#%e5%ad%a6%e4%b9%a0%e8%ae%a1%e5%88%92&#34; class=&#34;heading-mark&#34;&gt;&#xD;&#xA;    &lt;svg class=&#34;octicon octicon-link&#34; viewBox=&#34;0 0 16 16&#34; version=&#34;1.1&#34; width=&#34;16&#34; height=&#34;16&#34; aria-hidden=&#34;true&#34;&gt;&lt;path d=&#34;m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z&#34;&gt;&lt;/path&gt;&lt;/svg&gt;&#xD;&#xA;  &lt;/a&gt;&#xD;&#xA;&lt;/h2&gt;&lt;h3 class=&#34;heading-element&#34; id=&#34;第一阶段硬件基础与算法框架1-3个月&#34;&gt;&lt;span&gt;第一阶段：硬件基础与算法框架（1-3个月）&lt;/span&gt;&#xD;&#xA;  &lt;a href=&#34;#%e7%ac%ac%e4%b8%80%e9%98%b6%e6%ae%b5%e7%a1%ac%e4%bb%b6%e5%9f%ba%e7%a1%80%e4%b8%8e%e7%ae%97%e6%b3%95%e6%a1%86%e6%9e%b61-3%e4%b8%aa%e6%9c%88&#34; class=&#34;heading-mark&#34;&gt;&#xD;&#xA;    &lt;svg class=&#34;octicon octicon-link&#34; viewBox=&#34;0 0 16 16&#34; version=&#34;1.1&#34; width=&#34;16&#34; height=&#34;16&#34; aria-hidden=&#34;true&#34;&gt;&lt;path d=&#34;m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z&#34;&gt;&lt;/path&gt;&lt;/svg&gt;&#xD;&#xA;  &lt;/a&gt;&#xD;&#xA;&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;目标&lt;/strong&gt;：掌握相机硬件全流程与深度学习基础能力&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;strong&gt;相机硬件专项&lt;/strong&gt;（4周）&#xA;&lt;ul&gt;&#xA;&lt;li&gt;学习《Computer Vision: Algorithms and Applications》第2章（成像原理）&lt;/li&gt;&#xA;&lt;li&gt;实践OpenCV相机标定模块（张正友标定法）&lt;/li&gt;&#xA;&lt;li&gt;使用MATLAB/ROS工具进行ISP流程模拟实验&lt;/li&gt;&#xA;&lt;li&gt;搭建图像质量评估体系（PSNR/SSIM → 新指标：LPIPS/CSIQ）&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;算法框架升级&lt;/strong&gt;（4周）&#xA;&lt;ul&gt;&#xA;&lt;li&gt;深度学习框架：&#xA;&lt;ul&gt;&#xA;&lt;li&gt;PyTorch高级特性（分布式训练/量化部署）&lt;/li&gt;&#xA;&lt;li&gt;ONNX/TensorRT部署实战（YOLOv8部署案例）&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;搭建算法基线：&#xA;&lt;ul&gt;&#xA;&lt;li&gt;复现YOLOv8改进策略（损失函数/标签分配）&lt;/li&gt;&#xA;&lt;li&gt;实现Mask2Former的实例分割pipeline&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h3 class=&#34;heading-element&#34; id=&#34;第二阶段立体视觉与深度估计4-6个月&#34;&gt;&lt;span&gt;第二阶段：立体视觉与深度估计（4-6个月）&lt;/span&gt;&#xD;&#xA;  &lt;a href=&#34;#%e7%ac%ac%e4%ba%8c%e9%98%b6%e6%ae%b5%e7%ab%8b%e4%bd%93%e8%a7%86%e8%a7%89%e4%b8%8e%e6%b7%b1%e5%ba%a6%e4%bc%b0%e8%ae%a14-6%e4%b8%aa%e6%9c%88&#34; class=&#34;heading-mark&#34;&gt;&#xD;&#xA;    &lt;svg class=&#34;octicon octicon-link&#34; viewBox=&#34;0 0 16 16&#34; version=&#34;1.1&#34; width=&#34;16&#34; height=&#34;16&#34; aria-hidden=&#34;true&#34;&gt;&lt;path d=&#34;m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z&#34;&gt;&lt;/path&gt;&lt;/svg&gt;&#xD;&#xA;  &lt;/a&gt;&#xD;&#xA;&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;目标&lt;/strong&gt;：建立三维视觉技术栈&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;strong&gt;单目深度估计&lt;/strong&gt;（4周）&#xA;&lt;ul&gt;&#xA;&lt;li&gt;精读Depth Anything论文（CVPR 2024）&lt;/li&gt;&#xA;&lt;li&gt;使用NYU Depth V2数据集训练改进模型&lt;/li&gt;&#xA;&lt;li&gt;设计轻量化方案（知识蒸馏→移动端部署）&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;双目立体匹配&lt;/strong&gt;（4周）&#xA;&lt;ul&gt;&#xA;&lt;li&gt;研究LightStereo的工业级优化策略&lt;/li&gt;&#xA;&lt;li&gt;在SceneFlow数据集上开展对比实验&lt;/li&gt;&#xA;&lt;li&gt;开发FPGA加速方案（HLS代码优化）&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;3D姿态估计&lt;/strong&gt;（4周）&#xA;&lt;ul&gt;&#xA;&lt;li&gt;复现PoseFormer的时序建模模块&lt;/li&gt;&#xA;&lt;li&gt;在Human3.6M数据集上优化推理速度&lt;/li&gt;&#xA;&lt;li&gt;探索FoundationPose的zero-shot能力&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h3 class=&#34;heading-element&#34; id=&#34;第三阶段slam与前沿技术7-9个月&#34;&gt;&lt;span&gt;第三阶段：SLAM与前沿技术（7-9个月）&lt;/span&gt;&#xD;&#xA;  &lt;a href=&#34;#%e7%ac%ac%e4%b8%89%e9%98%b6%e6%ae%b5slam%e4%b8%8e%e5%89%8d%e6%b2%bf%e6%8a%80%e6%9c%af7-9%e4%b8%aa%e6%9c%88&#34; class=&#34;heading-mark&#34;&gt;&#xD;&#xA;    &lt;svg class=&#34;octicon octicon-link&#34; viewBox=&#34;0 0 16 16&#34; version=&#34;1.1&#34; width=&#34;16&#34; height=&#34;16&#34; aria-hidden=&#34;true&#34;&gt;&lt;path d=&#34;m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z&#34;&gt;&lt;/path&gt;&lt;/svg&gt;&#xD;&#xA;  &lt;/a&gt;&#xD;&#xA;&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;目标&lt;/strong&gt;：构建SLAM技术体系并追踪前沿&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;strong&gt;经典SLAM系统&lt;/strong&gt;（5周）&#xA;&lt;ul&gt;&#xA;&lt;li&gt;手撕ORB-SLAM3核心模块（特征提取/优化）&lt;/li&gt;&#xA;&lt;li&gt;在TUM数据集上完成完整轨迹评测&lt;/li&gt;&#xA;&lt;li&gt;开发ROS实时运行系统&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;深度学习SLAM&lt;/strong&gt;（4周）&#xA;&lt;ul&gt;&#xA;&lt;li&gt;分析DROID-SLAM的BA优化策略&lt;/li&gt;&#xA;&lt;li&gt;复现SplaTAM的Gaussian Splatting实现&lt;/li&gt;&#xA;&lt;li&gt;在Replica数据集进行三维重建对比&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;论文精读计划&lt;/strong&gt;（持续）&#xA;&lt;ul&gt;&#xA;&lt;li&gt;每周精读2篇CVPR/ICCV最新论文&lt;/li&gt;&#xA;&lt;li&gt;建立技术趋势分析文档（GitHub仓库维护）&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h3 class=&#34;heading-element&#34; id=&#34;第四阶段工程化实战10-12个月&#34;&gt;&lt;span&gt;第四阶段：工程化实战（10-12个月）&lt;/span&gt;&#xD;&#xA;  &lt;a href=&#34;#%e7%ac%ac%e5%9b%9b%e9%98%b6%e6%ae%b5%e5%b7%a5%e7%a8%8b%e5%8c%96%e5%ae%9e%e6%88%9810-12%e4%b8%aa%e6%9c%88&#34; class=&#34;heading-mark&#34;&gt;&#xD;&#xA;    &lt;svg class=&#34;octicon octicon-link&#34; viewBox=&#34;0 0 16 16&#34; version=&#34;1.1&#34; width=&#34;16&#34; height=&#34;16&#34; aria-hidden=&#34;true&#34;&gt;&lt;path d=&#34;m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z&#34;&gt;&lt;/path&gt;&lt;/svg&gt;&#xD;&#xA;  &lt;/a&gt;&#xD;&#xA;&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;目标&lt;/strong&gt;：打造完整的项目闭环&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;strong&gt;工业级项目开发&lt;/strong&gt;（8周）&#xA;&lt;ul&gt;&#xA;&lt;li&gt;设计端到端视觉系统：从相机选型（IMX477 vs OV4689）到算法部署&lt;/li&gt;&#xA;&lt;li&gt;开发自动化标定工具链（含异常检测模块）&lt;/li&gt;&#xA;&lt;li&gt;构建质量监控系统（Drift检测/在线校准）&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;性能优化专项&lt;/strong&gt;（4周）&#xA;&lt;ul&gt;&#xA;&lt;li&gt;算法级优化：模型剪枝（LayerDrop）&lt;/li&gt;&#xA;&lt;li&gt;硬件级优化：GPU TensorCore加速&lt;/li&gt;&#xA;&lt;li&gt;系统级优化：多线程流水线设计&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;作品集构建&lt;/strong&gt;（持续）&#xA;&lt;ul&gt;&#xA;&lt;li&gt;GitHub维护3个高质量项目：&#xA;&lt;ol&gt;&#xA;&lt;li&gt;实时多目标跟踪系统&lt;/li&gt;&#xA;&lt;li&gt;嵌入式双目深度解决方案&lt;/li&gt;&#xA;&lt;li&gt;基于NeRF的SLAM系统&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;撰写技术博客（Medium/知乎专栏）&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h3 class=&#34;heading-element&#34; id=&#34;学习资源推荐&#34;&gt;&lt;span&gt;学习资源推荐：&lt;/span&gt;&#xD;&#xA;  &lt;a href=&#34;#%e5%ad%a6%e4%b9%a0%e8%b5%84%e6%ba%90%e6%8e%a8%e8%8d%90&#34; class=&#34;heading-mark&#34;&gt;&#xD;&#xA;    &lt;svg class=&#34;octicon octicon-link&#34; viewBox=&#34;0 0 16 16&#34; version=&#34;1.1&#34; width=&#34;16&#34; height=&#34;16&#34; aria-hidden=&#34;true&#34;&gt;&lt;path d=&#34;m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z&#34;&gt;&lt;/path&gt;&lt;/svg&gt;&#xD;&#xA;  &lt;/a&gt;&#xD;&#xA;&lt;/h3&gt;&lt;ol&gt;&#xA;&lt;li&gt;硬件方向：《CMOS图像传感器电路设计》&lt;/li&gt;&#xA;&lt;li&gt;算法方向：《Multiple View Geometry in Computer Vision》&lt;/li&gt;&#xA;&lt;li&gt;工程实践：《CUDA C++ Best Practices Guide》&lt;/li&gt;&#xA;&lt;li&gt;论文库：CVF Open Access + arXiv每日推送&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h3 class=&#34;heading-element&#34; id=&#34;关键实施策略&#34;&gt;&lt;span&gt;关键实施策略：&lt;/span&gt;&#xD;&#xA;  &lt;a href=&#34;#%e5%85%b3%e9%94%ae%e5%ae%9e%e6%96%bd%e7%ad%96%e7%95%a5&#34; class=&#34;heading-mark&#34;&gt;&#xD;&#xA;    &lt;svg class=&#34;octicon octicon-link&#34; viewBox=&#34;0 0 16 16&#34; version=&#34;1.1&#34; width=&#34;16&#34; height=&#34;16&#34; aria-hidden=&#34;true&#34;&gt;&lt;path d=&#34;m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z&#34;&gt;&lt;/path&gt;&lt;/svg&gt;&#xD;&#xA;  &lt;/a&gt;&#xD;&#xA;&lt;/h3&gt;&lt;ol&gt;&#xA;&lt;li&gt;建立技术雷达图：每月更新各技术维度能力值&lt;/li&gt;&#xA;&lt;li&gt;参与Kaggle竞赛：至少完成2个计算机视觉赛事&lt;/li&gt;&#xA;&lt;li&gt;硬件投入：搭建含Jetson Orin+工业相机的开发平台&lt;/li&gt;&#xA;&lt;li&gt;参加CVPR/IROS等会议（线上资源）了解工业界最新需求&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;建议每周保持30小时有效学习时间（含项目实践），重点关注技术深度的纵向突破而非广度覆盖，每阶段结束时输出可展示的成果物。同时建议与行业从业者保持交流（如GitHub贡献、技术社区答疑），培养工程思维和产品意识。&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
